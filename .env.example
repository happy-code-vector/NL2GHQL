# LLM Provider Configuration
# Copy this file to .env and fill in your values

# Provider: openai, vllm, or mock
LLM_PROVIDER=mock

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_MODEL=gpt-4o
# OPENAI_BASE_URL=https://api.openai.com/v1

# vLLM Configuration (Local Qwen Model)
VLLM_API_KEY=dummy
VLLM_MODEL=models/hermes_miner
VLLM_BASE_URL=http://localhost:8000/v1

# LLM Parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=1024

# Qdrant Configuration
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=graphql_schema

# Model Paths
MODEL_PATH=models/hermes_miner
SCHEMA_PATH=data/schemas/schema_subnet.json

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Debug Mode
DEBUG=false
